{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa3b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import math\n",
    "import heapq\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07f70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(text):\n",
    "    probabilities = {}\n",
    "    total_chars = len(text)\n",
    "    for char in text:\n",
    "        if char in probabilities:\n",
    "            probabilities[char] += 1\n",
    "        else:\n",
    "            probabilities[char] = 1\n",
    "    for char, count in probabilities.items():\n",
    "        probabilities[char] = count / total_chars\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1f7b20",
   "metadata": {},
   "source": [
    "# Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0fec799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanNode:\n",
    "    def __init__(self, char, frequency):\n",
    "        self.char = char\n",
    "        self.frequency = frequency\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.frequency < other.frequency\n",
    "\n",
    "\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = 0\n",
    "    for prob in probabilities.values():\n",
    "        entropy += prob * math.log2(1 / prob)\n",
    "    return entropy\n",
    "\n",
    "def build_huffman_tree(probabilities):\n",
    "    priority_queue = [HuffmanNode(char, freq) for char, freq in probabilities.items()]\n",
    "    heapq.heapify(priority_queue)\n",
    "    while len(priority_queue) > 1:\n",
    "        left = heapq.heappop(priority_queue)\n",
    "        right = heapq.heappop(priority_queue)\n",
    "        merged = HuffmanNode(None, left.frequency + right.frequency)\n",
    "        merged.left = left\n",
    "        merged.right = right\n",
    "        heapq.heappush(priority_queue, merged)\n",
    "    return priority_queue[0]\n",
    "\n",
    "def generate_huffman_codes(root, current_code, codes):\n",
    "    if root is None:\n",
    "        return\n",
    "    if root.char is not None:\n",
    "        codes[root.char] = current_code\n",
    "        return\n",
    "    generate_huffman_codes(root.left, current_code + \"0\", codes)\n",
    "    generate_huffman_codes(root.right, current_code + \"1\", codes)\n",
    "\n",
    "def encode_huffman(text, codes):\n",
    "    encoded_text = \"\"\n",
    "    for char in text:\n",
    "        if char in codes:\n",
    "            encoded_text += codes[char]\n",
    "        else:\n",
    "            # If the character is not in the Huffman codes, raise an error or handle it accordingly\n",
    "            raise ValueError(f\"Character '{char}' cannot be encoded using Huffman coding.\")\n",
    "    return encoded_text\n",
    "\n",
    "def decode_huffman(encoded_text, huffman_tree):\n",
    "    decoded_text = \"\"\n",
    "    current_node = huffman_tree\n",
    "    for bit in encoded_text:\n",
    "        if bit == \"0\":\n",
    "            current_node = current_node.left\n",
    "        else:\n",
    "            current_node = current_node.right\n",
    "        if current_node.char is not None:\n",
    "            decoded_text += current_node.char\n",
    "            current_node = huffman_tree\n",
    "    return decoded_text\n",
    "\n",
    "def calculate_average_length(probabilities, codes):\n",
    "    average_length = sum(prob * len(codes[char]) for char, prob in probabilities.items())\n",
    "    return average_length\n",
    "\n",
    "def calculate_efficiency(average_length, entropy):\n",
    "    return (entropy / average_length) * 100\n",
    "\n",
    "def process_huffman_text(operation):\n",
    "    text = get_input_text()\n",
    "    if not text:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter some text.\")\n",
    "        return\n",
    "\n",
    "    probabilities = calculate_probability(text)\n",
    "    \n",
    "     # Check if there are characters in the text that cannot be compared using Huffman coding\n",
    "    invalid_chars = [char for char in text if char not in probabilities]\n",
    "    if invalid_chars:\n",
    "        messagebox.showwarning(\"Warning\", f\"The following characters cannot be compared using Huffman coding: {', '.join(invalid_chars)}\")\n",
    "        return\n",
    "    \n",
    "    huffman_tree = build_huffman_tree(probabilities)\n",
    "    huffman_codes = {}\n",
    "    generate_huffman_codes(huffman_tree, \"\", huffman_codes)\n",
    "    encoded_text = encode_huffman(text, huffman_codes)\n",
    "\n",
    "    if operation == \"compress\":\n",
    "        decoded_text = decode_huffman(encoded_text, huffman_tree)\n",
    "        additional_info = f\"Decoded text: {decoded_text}\\n\"\n",
    "    else:\n",
    "        additional_info = \"\"\n",
    "\n",
    "    bits_before, bits_after = len(text) * 8, len(encoded_text)\n",
    "    reduction_in_bits = bits_before - bits_after\n",
    "    compression_ratio = bits_before / bits_after\n",
    "    compression_ratio_percentage = (1 - (bits_after / bits_before)) * 100 if bits_before != 0 else 0 \n",
    "    space_usage_ratio = (bits_after / bits_before) * 100\n",
    "    entropy = calculate_entropy(probabilities)\n",
    "    average_length = calculate_average_length(probabilities, huffman_codes)\n",
    "    efficiency = calculate_efficiency(average_length, entropy)\n",
    "    efficiency_message = \"Compression was effective.\" if bits_after < bits_before else \"Compression was not effective.\"\n",
    "    \n",
    "    output_text = f\"Original text: {text}\\n\"\n",
    "    output_text += f\"Encoded text: {encoded_text}\\n\"\n",
    "    output_text += additional_info\n",
    "    output_text += f\"Bits before encoding: {bits_before}\\n\"\n",
    "    output_text += f\"Bits after encoding: {bits_after}\\n\"\n",
    "    output_text += f\"Reduction in bits: {reduction_in_bits}\\n\"\n",
    "    output_text += f\"Compression ratio : {compression_ratio}\\n\"\n",
    "    output_text += f\"Compression ratio percentage(%): {compression_ratio_percentage:.2f}%\\n\"\n",
    "    output_text += f\"Space usage ratio (%): {space_usage_ratio:.2f}%\\n\"\n",
    "    output_text += \"Probability of occurrence for each character:\\n\"\n",
    "    for char, prob in probabilities.items():\n",
    "        output_text += f\"- {char}: {prob}\\n\"\n",
    "    output_text += f\"Entropy: {entropy}\\n\"\n",
    "    output_text += f\"Average length: {average_length}\\n\"\n",
    "    output_text += f\"Efficiency of this message: {efficiency}\\n\"\n",
    "    output_text += f\"Efficiency message: {efficiency_message}\\n\"\n",
    "\n",
    "    update_output_text(output_text)\n",
    "\n",
    "def get_input_text():\n",
    "    return text_input.get(\"1.0\", tk.END).strip()\n",
    "\n",
    "def update_output_text(text):\n",
    "    text_output.delete(\"1.0\", tk.END)\n",
    "    text_output.insert(\"1.0\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2513c1",
   "metadata": {},
   "source": [
    "# RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68beb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_rle(text):\n",
    "    encoded_text = ''\n",
    "    count = 1\n",
    "    prev_char = ''\n",
    "    no_of_vec = 0\n",
    "    max_count = 0\n",
    "    if not text:\n",
    "        return '', 0, 0, {}, 0, 0, 0\n",
    "\n",
    "    for char in text:\n",
    "        if char != prev_char:\n",
    "            no_of_vec += 1\n",
    "            if prev_char:\n",
    "                encoded_text += str(count) + prev_char\n",
    "            count = 1\n",
    "            prev_char = char\n",
    "        else:\n",
    "            count += 1\n",
    "        if max_count < count:\n",
    "            max_count = count\n",
    "    encoded_text += str(count) + prev_char\n",
    "    \n",
    "    bits_before = len(text) * 8\n",
    "    bits_after = no_of_vec * ( 8 + (math.ceil(math.log(max_count+1, 2))) )\n",
    "    compression_ratio = (bits_before / bits_after)*100\n",
    "    probabilities = calculate_probability(text)\n",
    "    entropy = calculate_entropy(probabilities)\n",
    "    average_length = calculate_average_length_rle(probabilities, encoded_text)\n",
    "    efficiency = calculate_efficiency(average_length, entropy)\n",
    "\n",
    "    return encoded_text, bits_before, bits_after, compression_ratio, probabilities, entropy, average_length, efficiency\n",
    "\n",
    "def calculate_average_length_rle(probabilities, encoded_text):\n",
    "    # In RLE, each character is followed by its count, so the average length\n",
    "    # is the sum of the lengths of the encoded characters.\n",
    "    average_length = len(encoded_text)\n",
    "    return average_length\n",
    "\n",
    "def decode_rle(encoded_text):\n",
    "    decoded_text = ''\n",
    "    count = ''\n",
    "    for char in encoded_text:\n",
    "        if char.isdigit():\n",
    "            count += char\n",
    "        else:\n",
    "            decoded_text += char * int(count)\n",
    "            count = ''\n",
    "    return decoded_text\n",
    "\n",
    "def compress_text_rle():\n",
    "    input_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter some text.\")\n",
    "        return\n",
    "    \n",
    "    encoded_text, bits_before, bits_after, compression_ratio, probabilities, entropy, average_length, efficiency= encode_rle(input_text)\n",
    "    decoded_text = decode_rle(encoded_text)\n",
    "\n",
    "    output_text = f\"Original text: {input_text}\\n\"\n",
    "    output_text += f\"Encoded text: {encoded_text}\\n\"\n",
    "    output_text += f\"Decoded text: {decoded_text}\\n\"\n",
    "    output_text += f\"Bits before encoding: {bits_before}\\n\"\n",
    "    output_text += f\"Bits after encoding: {bits_after}\\n\"\n",
    "    output_text += f\"Compression ratio (%): {compression_ratio}\\n\"\n",
    "    output_text += \"Probability of occurrence for each character:\\n\"\n",
    "    for char, prob in probabilities.items():\n",
    "        output_text += f\"- {char}: {prob}\\n\"\n",
    "    output_text += f\"Entropy: {entropy}\\n\"\n",
    "    output_text += f\"Average length: {average_length}\\n\"\n",
    "    output_text += f\"Efficiency of this message: {efficiency}\\n\"\n",
    "    \n",
    "    text_output.delete(\"1.0\", tk.END)\n",
    "    text_output.insert(\"1.0\", output_text)\n",
    "\n",
    "    # Clear the canvas\n",
    "    canvas.delete(\"all\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606c26b",
   "metadata": {},
   "source": [
    "# Text Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e0608aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_arith = None \n",
    "\n",
    "class ArithmeticCoding:\n",
    "    def __init__(self, probabilities):\n",
    "        self.probabilities = probabilities\n",
    "        self.low_range = {}\n",
    "        self.high_range = {}\n",
    "        self.cumulative_prob = {}\n",
    "        self.initialize_ranges()\n",
    "\n",
    "    def initialize_ranges(self):\n",
    "        low = 0.0\n",
    "        for symbol, prob in self.probabilities.items():\n",
    "            self.low_range[symbol] = low\n",
    "            self.high_range[symbol] = low + prob\n",
    "            self.cumulative_prob[symbol] = low\n",
    "            low += prob\n",
    "\n",
    "    def encode(self, sequence):\n",
    "        low = 0.0\n",
    "        high = 1.0\n",
    "        for symbol in sequence:\n",
    "            range_width = high - low\n",
    "            high = low + range_width * self.high_range[symbol]\n",
    "            low = low + range_width * self.low_range[symbol]\n",
    "        return (low + high) / 2\n",
    "\n",
    "    def decode(self, code, length):\n",
    "        sequence = []\n",
    "        for _ in range(length):\n",
    "            found_symbol = False\n",
    "            for symbol, low in self.low_range.items():\n",
    "                if low <= code < self.high_range[symbol]:\n",
    "                    sequence.append(symbol)\n",
    "                    range_width = self.high_range[symbol] - low\n",
    "                    code = (code - low) / range_width\n",
    "                    found_symbol = True\n",
    "                    break\n",
    "            if not found_symbol:\n",
    "                raise ValueError(\"Invalid compression code\")\n",
    "        return ''.join(sequence)\n",
    "    \n",
    "    def encode_length(self, symbol):\n",
    "        # Implement logic to calculate the length of the encoded code for the symbol\n",
    "        encoded_code = self.encode(symbol)\n",
    "        # Example: return the length of the string representation of the float\n",
    "        return len(str(encoded_code))\n",
    "\n",
    "def get_probabilities():\n",
    "    probabilities = {}\n",
    "    prob_input = text_probabilities.get(\"1.0\", tk.END).strip()\n",
    "    prob_lines = prob_input.split(\"\\n\")\n",
    "    for line in prob_lines:\n",
    "        symbol, prob = line.split(\":\")\n",
    "        probabilities[symbol.strip()] = float(prob)\n",
    "    return probabilities\n",
    "\n",
    "def calculate_metrics(original_text, compressed_code, arithmetic_coder):\n",
    "    original_text_bits = len(original_text) * 8  # Assuming 8 bits per character\n",
    "    compressed_bits = len(compressed_code)\n",
    "    compression_ratio = (original_text_bits / compressed_bits) * 100\n",
    "    probabilities = get_probabilities()\n",
    "    entropy = calculate_entropy_arith(probabilities)\n",
    "    \n",
    "    average_length = calculate_average_length_arith(probabilities, arithmetic_coder)\n",
    "    efficiency_arith = entropy / average_length\n",
    "    return original_text_bits, compressed_bits, compression_ratio, entropy, average_length, efficiency_arith\n",
    "\n",
    "def calculate_entropy_arith(probabilities):\n",
    "    # Calculate the entropy using the probabilities\n",
    "    entropy = -sum(prob * math.log2(prob) for prob in probabilities.values())\n",
    "    return entropy\n",
    "\n",
    "def calculate_average_length_arith(probabilities, arithmetic_coder):\n",
    "    # Calculate the average length of the encoded symbols\n",
    "    average_length = sum(arithmetic_coder.encode_length(symbol) * prob for symbol, prob in probabilities.items())\n",
    "    return average_length\n",
    "\n",
    "def compress_text_arithmetic():\n",
    "    global efficiency_arith\n",
    "    input_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter some text.\")\n",
    "        return\n",
    "\n",
    "    probabilities = get_probabilities()\n",
    "\n",
    "    arithmetic_coder = ArithmeticCoding(probabilities)\n",
    "    compressed_code = str(arithmetic_coder.encode(input_text))  # Convert to string\n",
    "\n",
    "    original_text_bits, compressed_bits, compression_ratio, entropy, average_length, efficiency_arith = calculate_metrics(input_text, compressed_code, arithmetic_coder)\n",
    "\n",
    "    output_text = f\"Original text: {input_text}\\n\"\n",
    "    output_text += f\"Compressed code: {compressed_code}\\n\"\n",
    "    output_text += f\"Original text bits: {original_text_bits}\\n\"\n",
    "    output_text += f\"Compressed bits: {compressed_bits}\\n\"\n",
    "    output_text += f\"Compression Ratio: {compression_ratio:.2f}%\\n\"\n",
    "    output_text += f\"Entropy: {entropy:.2f}\\n\"\n",
    "    output_text += f\"Average Length: {average_length:.2f}\\n\"\n",
    "    output_text += f\"Efficiency: {efficiency_arith:.2f}\\n\"\n",
    "\n",
    "    text_output.delete(\"1.0\", tk.END)\n",
    "    text_output.insert(\"1.0\", output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805f6b5",
   "metadata": {},
   "source": [
    "# Golomb-Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0619e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_golomb = None  # Define efficiency as a global variable\n",
    "\n",
    "# Golomb-Rice encoding functions\n",
    "def golomb_rice_encode(sequence, M):\n",
    "    # Generate RLE from the sequence\n",
    "    rle_sequence_golomb = []\n",
    "    char_sequence = []\n",
    "    count = 1\n",
    "    for i in range(1, len(sequence)):\n",
    "        if sequence[i] == sequence[i - 1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            rle_sequence_golomb.append((sequence[i-1], count))  # Storing both symbol and count\n",
    "            count = 1\n",
    "    rle_sequence_golomb.append((sequence[-1], count))  # Storing the last symbol and its count\n",
    "\n",
    "    if not rle_sequence_golomb:\n",
    "        raise ValueError(\"Empty sequence.\")\n",
    "\n",
    "    codewords = {}\n",
    "    for char, count in rle_sequence_golomb:\n",
    "        # Generate Golomb-Rice codeword for count\n",
    "        count_codeword = golomb_rice_encode_count(count, M)\n",
    "        # Store the Golomb-Rice codeword along with the character\n",
    "        codewords[(char, count)] = count_codeword\n",
    "\n",
    "    # Return the encoded sequence and the codewords\n",
    "    return rle_sequence_golomb, codewords\n",
    "\n",
    "def golomb_rice_decode(encoded, codewords, M):\n",
    "    decoded_sequence = []\n",
    "    for char, count in encoded:\n",
    "        # Decode the count using the Golomb-Rice codeword\n",
    "        count_codeword = codewords[(char, count)]\n",
    "        decoded_value = golomb_rice_decode_count(count_codeword, M)\n",
    "        # Append the decoded value to the sequence\n",
    "        decoded_sequence.extend([char] * decoded_value)\n",
    "    # Return the decoded sequence\n",
    "    return decoded_sequence\n",
    "\n",
    "def golomb_rice_encode_count(value, M):\n",
    "    quotient = value // M\n",
    "    remainder = value % M\n",
    "    \n",
    "    # Encode quotient in unary; a sequence of 1s followed by a 0.\n",
    "    unary = '1' * quotient + '0'\n",
    "    \n",
    "    # Encode remainder in binary. The length of the binary representation is log2(M).\n",
    "    binary_length = math.ceil(math.log2(M))\n",
    "    binary = format(remainder, f'0{binary_length}b')\n",
    "    \n",
    "    return unary + binary\n",
    "\n",
    "def golomb_rice_decode_count(encoded, M):\n",
    "    decoded_value = 0\n",
    "    # Extract the quotient\n",
    "    while encoded[0] == '1':\n",
    "        decoded_value += 1\n",
    "        encoded = encoded[1:]\n",
    "    # Skip over the separator '0'\n",
    "    encoded = encoded[1:]\n",
    "    # Extract the binary part\n",
    "    remainder = ''\n",
    "    while len(remainder) < math.ceil(math.log2(M)):\n",
    "        remainder += encoded[0]\n",
    "        encoded = encoded[1:]\n",
    "    # Convert the binary part to integer\n",
    "    remainder_value = int(remainder, 2)\n",
    "    # Decode the value using the quotient and remainder\n",
    "    decoded_value = decoded_value * M + remainder_value\n",
    "    return decoded_value\n",
    "\n",
    "\n",
    "def calculate_average_length_golomb(rle_sequence_golomb, codewords, probabilities):\n",
    "    total_length = 0\n",
    "\n",
    "    for char, count in rle_sequence_golomb:\n",
    "        probability = probabilities[char]\n",
    "        codeword_length = len(codewords[(char, count)])\n",
    "        total_length += probability * codeword_length\n",
    "\n",
    "    return total_length\n",
    "\n",
    "\n",
    "def process_golomb_text(operation):\n",
    "    global efficiency_golomb \n",
    "    canvas.delete(\"all\")\n",
    "    try:\n",
    "        sequence = text_input.get(\"1.0\", tk.END).strip()\n",
    "        M = int(entry_M.get())\n",
    "        if M <= 0:\n",
    "            raise ValueError(\"M should be a positive integer.\")\n",
    "\n",
    "        # Generate RLE from the sequence\n",
    "        rle_sequence_golomb, codewords = golomb_rice_encode(sequence, M)\n",
    "\n",
    "        if not rle_sequence_golomb:\n",
    "            raise ValueError(\"Empty sequence.\")\n",
    "\n",
    "       # Calculate bits before encoding\n",
    "        if all(char in '01' for char in sequence):\n",
    "            original_bits = len(sequence)  # Each character is considered as one bit\n",
    "        else:\n",
    "            original_bits = len(sequence) * 8  # Each character is considered as one byte (eight bits)\n",
    "\n",
    "        # Calculate bits after encoding\n",
    "        encoded_bits = sum(len(codewords[(char, count)]) for char, count in rle_sequence_golomb)\n",
    "        encoded_code = ''.join(codewords[(char, count)] for char, count in rle_sequence_golomb)\n",
    "\n",
    "        if operation == \"compress\":\n",
    "            decoded_text = golomb_rice_decode(rle_sequence_golomb, codewords, M)\n",
    "            decoded_sequence = ''.join(decoded_text)\n",
    "            additional_info = f\"Decoded text: {decoded_sequence}\\n\"\n",
    "        else:\n",
    "            additional_info = \"\"\n",
    "            \n",
    "\n",
    "        # Calculate compression ratio\n",
    "        compression_ratio = original_bits/encoded_bits\n",
    "               \n",
    "        # Calculate probabilities\n",
    "        probabilities = calculate_probability(sequence)\n",
    "\n",
    "        # Calculate entropy\n",
    "        # Calculate entropy of the original text\n",
    "        entropy = calculate_entropy(probabilities)\n",
    "\n",
    "        # Calculate average length\n",
    "        average_length = calculate_average_length_golomb(rle_sequence_golomb, codewords, probabilities)\n",
    "\n",
    "        # Calculate efficiency\n",
    "        efficiency_golomb = entropy / average_length * 100\n",
    "\n",
    "        # Prepare output text\n",
    "        output_text = f\"Original sequence: {sequence}\\n\"\n",
    "        output_text += f\"Encoded code:\\n{encoded_code}\\n\"\n",
    "        output_text += additional_info\n",
    "        output_text += f\"Character Probabilities:\\n\"\n",
    "        # Calculate probabilities of characters in the original text\n",
    "        for char, prob in probabilities.items():\n",
    "            output_text += f\"- {char}: {prob}\\n\"\n",
    "        output_text += f\"Codewords:\\n\"\n",
    "        for (char, count), codeword in codewords.items():\n",
    "            output_text += f\"- {char} ({count}): {codeword}\\n\"\n",
    "        output_text += f\"Bits before encoding: {original_bits}\\n\"\n",
    "        output_text += f\"Bits after encoding: {encoded_bits}\\n\"\n",
    "        output_text += f\"Compression ratio: {compression_ratio:.2f}\\n\"\n",
    "        output_text += f\"Entropy: {entropy:.2f} bits/character\\n\"\n",
    "        output_text += f\"Average Length: {average_length:.2f} bits/character\\n\"\n",
    "        output_text += f\"Efficiency: {efficiency_golomb:.2f}%\\n\"\n",
    "\n",
    "        text_output.delete(\"1.0\", tk.END)\n",
    "        text_output.insert(\"1.0\", output_text)\n",
    "        \n",
    "    except ValueError as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f064b7c",
   "metadata": {},
   "source": [
    "# LZW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24fe3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_lzw = None \n",
    "\n",
    "def LZW_compress(text):\n",
    "    # Initialize dictionary with ASCII characters\n",
    "    dictionary_size = 256\n",
    "    dictionary = {chr(i): i for i in range(dictionary_size)}\n",
    "    result = []\n",
    "    current_string = \"\"\n",
    "    for char in text:\n",
    "        new_string = current_string + char\n",
    "        if new_string in dictionary:\n",
    "            current_string = new_string\n",
    "        else:\n",
    "            result.append(dictionary[current_string])\n",
    "            # Add new string to dictionary\n",
    "            dictionary[new_string] = dictionary_size\n",
    "            dictionary_size += 1\n",
    "            current_string = char\n",
    "    if current_string:\n",
    "        result.append(dictionary[current_string])\n",
    "    return result\n",
    "\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = 0\n",
    "    for prob in probabilities.values():\n",
    "        entropy -= prob * math.log2(prob)\n",
    "    return entropy\n",
    "\n",
    "def calculate_efficiency(average_length, entropy):\n",
    "    return entropy / average_length\n",
    "\n",
    "def compress_text_lzw():\n",
    "    global efficiency_lzw\n",
    "    input_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter some text.\")\n",
    "        return\n",
    "\n",
    "    compressed_text = LZW_compress(input_text)\n",
    "\n",
    "    # Calculate probabilities of characters in the original text\n",
    "    probabilities = calculate_probability(input_text)\n",
    "\n",
    "    # Calculate entropy of the original text\n",
    "    entropy = calculate_entropy(probabilities)\n",
    "\n",
    "    # Calculate average length of the compressed LZW output\n",
    "    average_length = len(compressed_text) *8  # Assuming each code takes 12 bits\n",
    "\n",
    "    # Calculate efficiency of the compressed LZW output\n",
    "    efficiency_lzw = calculate_efficiency(average_length, entropy)\n",
    "\n",
    "    bits_before = len(input_text) * 8\n",
    "    bits_after = average_length\n",
    "    compression_ratio = (bits_before / bits_after)*100\n",
    "\n",
    "    output_text = f\"Original text: {input_text}\\n\"\n",
    "    output_text += f\"Compressed text: {compressed_text}\\n\"\n",
    "    output_text += f\"Bits before encoding: {bits_before}\\n\"\n",
    "    output_text += f\"Bits after encoding: {bits_after}\\n\"\n",
    "    output_text += f\"Compression ratio (%): {compression_ratio}%\\n\"\n",
    "    output_text += \"Probability of occurrence for each character:\\n\"\n",
    "    for char, prob in probabilities.items():\n",
    "        output_text += f\"- {char}: {prob}\\n\"\n",
    "    output_text += f\"Entropy: {entropy}\\n\"\n",
    "    output_text += f\"Average length: {average_length}\\n\"\n",
    "    output_text += f\"Efficiency of this message: {efficiency_lzw}\\n\"\n",
    "\n",
    "    text_output.delete(\"1.0\", tk.END)\n",
    "    text_output.insert(\"1.0\", output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20192f68",
   "metadata": {},
   "source": [
    "# Optimal Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4706e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_optimal_technique():\n",
    "    input_text = text_input.get(\"1.0\", tk.END).strip()\n",
    "    if not input_text:\n",
    "        messagebox.showwarning(\"Warning\", \"Please enter some text.\")\n",
    "        return\n",
    "\n",
    "    # Calculate probabilities and other metrics for Huffman encoding\n",
    "    probabilities_huffman = calculate_probability(input_text)\n",
    "    huffman_tree = build_huffman_tree(probabilities_huffman)\n",
    "    huffman_codes = {}\n",
    "    generate_huffman_codes(huffman_tree, \"\", huffman_codes)\n",
    "    average_length_huffman = calculate_average_length(probabilities_huffman, huffman_codes)\n",
    "    entropy_huffman = calculate_entropy(probabilities_huffman)\n",
    "    efficiency_huffman = calculate_efficiency(average_length_huffman, entropy_huffman)\n",
    "\n",
    "    # Calculate probabilities and other metrics for RLE encoding\n",
    "    _, _, _, _, probabilities_rle, entropy_rle, average_length_rle, efficiency_rle = encode_rle(input_text)\n",
    "    \n",
    "    # Choose the optimal technique based on efficiency\n",
    "    optimal_technique = max(\n",
    "        (\"Golomb-Rice Encoding\", efficiency_golomb),\n",
    "        (\"Huffman Encoding\", efficiency_huffman),\n",
    "        (\"Run Length Encoding (RLE)\", efficiency_rle),\n",
    "        (\"Arithmetic Encoding\", efficiency_arith),\n",
    "        (\"LZW Compression\", efficiency_lzw),\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "\n",
    "    messagebox.showinfo(\"Optimal Technique\", f\"{optimal_technique[0]} is recommended for this text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47f98a",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6a20df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Compression Tool\")\n",
    "\n",
    "frame_input = tk.Frame(root)\n",
    "frame_input.pack(padx=10, pady=10)\n",
    "\n",
    "label_input = tk.Label(frame_input, text=\"Enter the text to be compressed:\")\n",
    "label_input.pack()\n",
    "\n",
    "text_input = tk.Text(frame_input, height=5, width=50)\n",
    "text_input.pack()\n",
    "\n",
    "label_probabilities = tk.Label(frame_input, text=\"Enter probabilities (e.g., 'a:0.5\\nb:0.3\\nc:0.2'):\")\n",
    "label_probabilities.pack()\n",
    "\n",
    "text_probabilities = tk.Text(frame_input, height=5, width=50)\n",
    "text_probabilities.pack()\n",
    "\n",
    "label_M = tk.Label(frame_input, text=\"Enter the M parameter:\")\n",
    "label_M.pack()\n",
    "entry_M = tk.Entry(frame_input)\n",
    "entry_M.pack()\n",
    "\n",
    "def compress_decode_huffman():\n",
    "    button_text = button_compress_decode_huffman.cget(\"text\")\n",
    "    if button_text == \"Compress (Huffman)\":\n",
    "        process_huffman_text(\"compress\")\n",
    "        button_compress_decode_huffman.config(text=\"Decode (Huffman)\")\n",
    "    else:\n",
    "        process_huffman_text(\"decode\")\n",
    "        button_compress_decode_huffman.config(text=\"Compress (Huffman)\")\n",
    "\n",
    "button_compress_decode_huffman = tk.Button(root, text=\"Compress (Huffman)\", command=compress_decode_huffman)\n",
    "button_compress_decode_huffman.pack(pady=5)\n",
    "\n",
    "button_compress_rle = tk.Button(root, text=\"Compress (Run Length Encoding)\", command=compress_text_rle)\n",
    "button_compress_rle.pack(pady=5)\n",
    "\n",
    "button_compress_arithmetic = tk.Button(root, text=\"Compress (Arithmetic Encoding)\", command=compress_text_arithmetic)\n",
    "button_compress_arithmetic.pack(pady=5)\n",
    "\n",
    "def compress_decode_golomb():\n",
    "    button_text = button_compress_decode_golomb.cget(\"text\")\n",
    "    if button_text == \"Compress (Golomb)\":\n",
    "        process_golomb_text(\"compress\")\n",
    "        button_compress_decode_golomb.config(text=\"Decode (Golomb)\")\n",
    "    else:\n",
    "        process_golomb_text(\"decode\")\n",
    "        button_compress_decode_golomb.config(text=\"Compress (Golomb)\")\n",
    "        \n",
    "button_compress_decode_golomb = tk.Button(root, text=\"Compress (Golomb)\", command=compress_decode_golomb)\n",
    "button_compress_decode_golomb.pack(pady=5)\n",
    "\n",
    "button_compress_lzw = tk.Button(root, text=\"Compress (LZW)\", command=compress_text_lzw)\n",
    "button_compress_lzw.pack(pady=5)\n",
    "\n",
    "button_optimal_technique = tk.Button(root, text=\"Choose Optimal Technique\", command=choose_optimal_technique)\n",
    "button_optimal_technique.pack(pady=5)\n",
    "\n",
    "frame_output = tk.Frame(root)\n",
    "frame_output.pack(padx=10, pady=10)\n",
    "\n",
    "label_output = tk.Label(frame_output, text=\"Compression/Decompression Details:\")\n",
    "label_output.pack()\n",
    "\n",
    "text_output = tk.Text(frame_output, height=20, width=90)\n",
    "text_output.pack()\n",
    "\n",
    "canvas = tk.Canvas(root, width=800, height=600)\n",
    "canvas.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d7a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
